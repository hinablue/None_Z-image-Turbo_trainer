# LongCat-Image 加速 LoRA 训练配置
# 使用 Rectified Flow 方法训练 10 步加速 LoRA

[model]
# Transformer 模型路径
dit = "/path/to/longcat-image/transformer"

# VAE 路径（可选，默认使用模型目录下的 vae）
# vae = "/path/to/longcat-image/vae"

# 输出目录
output_dir = "output/longcat_turbo"
output_name = "longcat-turbo-lora"

[turbo]
# 目标加速步数
turbo_steps = 10

# 时间步 shift 参数（LongCat 使用动态 shift）
use_dynamic_shifting = true
base_shift = 0.5
max_shift = 1.15

# 锚点抖动幅度
jitter_scale = 0.02

# 使用锚点采样（推荐开启）
use_anchor = true

[lora]
# LoRA rank（加速训练建议 32-64）
network_dim = 32
network_alpha = 16

# 使用 PEFT 库（LongCat 推荐）
use_peft = true

[training]
optimizer_type = "AdamW8bit"
learning_rate = 1e-4
weight_decay = 0.01
lr_scheduler = "cosine"
lr_warmup_steps = 100
lr_num_cycles = 1
num_train_epochs = 10
save_every_n_epochs = 1
gradient_accumulation_steps = 2
seed = 42

# SNR 加权
snr_gamma = 5.0
snr_floor = 0.1

[advanced]
max_grad_norm = 1.0
gradient_checkpointing = true
mixed_precision = "bf16"

[dataset]
batch_size = 1
num_workers = 4
shuffle = true
enable_bucket = true

[[dataset.sources]]
cache_directory = "/path/to/your/dataset/cache"
num_repeats = 10
resolution_limit = 1024

